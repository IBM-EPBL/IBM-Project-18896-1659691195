{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jIagCbF67CoG"
      },
      "source": [
        "<span id=\"notebook-env\" notebook-env=\"production\"></span> <span\n",
        "id=\"notebook-subdomain-isolated\"\n",
        "notebook-subdomain-isolated=\"true\"></span>\n",
        "\n",
        "**1. The given dataset is downloaded as \"Flowers-Dataset\"**\n",
        "\n",
        "**2. Image Augmentation**<a href=\"https://github.com/IBM-EPBL/IBM-Project-1257-1658381885/blob/24330d3bc5de5f89f6317e12ffdcb3110a96f37a/Assignments/Dineshraja%20V/#2.-Image-Augmentation\" class=\"anchor-link\">¶</a>\n",
        "====================================================================================================================================================================================================================\n",
        "\n",
        "It is a technique used to increase the image with some modification. To\n",
        "overcome overfitting we are using augmentation.\n",
        "\n",
        "In \\[1\\]:\n",
        "\n",
        "    !pip install tensorflow\n",
        "\n",
        "    Requirement already satisfied: tensorflow in c:\\users\\dineshraja\\anaconda3\\lib\\site-packages (2.10.0)\n",
        "    Requirement already satisfied: keras<2.11,>=2.10.0 in c:\\users\\dineshraja\\anaconda3\\lib\\site-packages (from tensorflow) (2.10.0)\n",
        "    Requirement already satisfied: packaging in c:\\users\\dineshraja\\anaconda3\\lib\\site-packages (from tensorflow) (20.9)\n",
        "    Requirement already satisfied: protobuf<3.20,>=3.9.2 in c:\\users\\dineshraja\\anaconda3\\lib\\site-packages (from tensorflow) (3.19.6)\n",
        "    Requirement already satisfied: grpcio<2.0,>=1.24.3 in c:\\users\\dineshraja\\anaconda3\\lib\\site-packages (from tensorflow) (1.49.1)\n",
        "    Requirement already satisfied: libclang>=13.0.0 in c:\\users\\dineshraja\\anaconda3\\lib\\site-packages (from tensorflow) (14.0.6)\n",
        "    Requirement already satisfied: wrapt>=1.11.0 in c:\\users\\dineshraja\\anaconda3\\lib\\site-packages (from tensorflow) (1.12.1)\n",
        "    Requirement already satisfied: h5py>=2.9.0 in c:\\users\\dineshraja\\anaconda3\\lib\\site-packages (from tensorflow) (2.10.0)\n",
        "    Requirement already satisfied: flatbuffers>=2.0 in c:\\users\\dineshraja\\anaconda3\\lib\\site-packages (from tensorflow) (22.9.24)\n",
        "    Requirement already satisfied: numpy>=1.20 in c:\\users\\dineshraja\\anaconda3\\lib\\site-packages (from tensorflow) (1.20.1)\n",
        "    Requirement already satisfied: opt-einsum>=2.3.2 in c:\\users\\dineshraja\\anaconda3\\lib\\site-packages (from tensorflow) (3.3.0)\n",
        "    Requirement already satisfied: termcolor>=1.1.0 in c:\\users\\dineshraja\\anaconda3\\lib\\site-packages (from tensorflow) (2.0.1)\n",
        "    Requirement already satisfied: google-pasta>=0.1.1 in c:\\users\\dineshraja\\anaconda3\\lib\\site-packages (from tensorflow) (0.2.0)\n",
        "    Requirement already satisfied: setuptools in c:\\users\\dineshraja\\anaconda3\\lib\\site-packages (from tensorflow) (52.0.0.post20210125)\n",
        "    Requirement already satisfied: absl-py>=1.0.0 in c:\\users\\dineshraja\\anaconda3\\lib\\site-packages (from tensorflow) (1.2.0)\n",
        "    Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in c:\\users\\dineshraja\\anaconda3\\lib\\site-packages (from tensorflow) (0.27.0)\n",
        "    Requirement already satisfied: typing-extensions>=3.6.6 in c:\\users\\dineshraja\\anaconda3\\lib\\site-packages (from tensorflow) (3.7.4.3)\n",
        "    Requirement already satisfied: six>=1.12.0 in c:\\users\\dineshraja\\anaconda3\\lib\\site-packages (from tensorflow) (1.15.0)\n",
        "    Requirement already satisfied: tensorflow-estimator<2.11,>=2.10.0 in c:\\users\\dineshraja\\anaconda3\\lib\\site-packages (from tensorflow) (2.10.0)\n",
        "    Requirement already satisfied: gast<=0.4.0,>=0.2.1 in c:\\users\\dineshraja\\anaconda3\\lib\\site-packages (from tensorflow) (0.4.0)\n",
        "    Requirement already satisfied: tensorboard<2.11,>=2.10 in c:\\users\\dineshraja\\anaconda3\\lib\\site-packages (from tensorflow) (2.10.1)\n",
        "    Requirement already satisfied: keras-preprocessing>=1.1.1 in c:\\users\\dineshraja\\anaconda3\\lib\\site-packages (from tensorflow) (1.1.2)\n",
        "    Requirement already satisfied: astunparse>=1.6.0 in c:\\users\\dineshraja\\anaconda3\\lib\\site-packages (from tensorflow) (1.6.3)\n",
        "    Requirement already satisfied: wheel<1.0,>=0.23.0 in c:\\users\\dineshraja\\anaconda3\\lib\\site-packages (from astunparse>=1.6.0->tensorflow) (0.36.2)\n",
        "    Requirement already satisfied: requests<3,>=2.21.0 in c:\\users\\dineshraja\\anaconda3\\lib\\site-packages (from tensorboard<2.11,>=2.10->tensorflow) (2.25.1)\n",
        "    Requirement already satisfied: markdown>=2.6.8 in c:\\users\\dineshraja\\anaconda3\\lib\\site-packages (from tensorboard<2.11,>=2.10->tensorflow) (3.4.1)\n",
        "    Requirement already satisfied: werkzeug>=1.0.1 in c:\\users\\dineshraja\\anaconda3\\lib\\site-packages (from tensorboard<2.11,>=2.10->tensorflow) (1.0.1)\n",
        "    Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in c:\\users\\dineshraja\\anaconda3\\lib\\site-packages (from tensorboard<2.11,>=2.10->tensorflow) (1.8.1)\n",
        "    Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in c:\\users\\dineshraja\\anaconda3\\lib\\site-packages (from tensorboard<2.11,>=2.10->tensorflow) (0.4.6)\n",
        "    Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in c:\\users\\dineshraja\\anaconda3\\lib\\site-packages (from tensorboard<2.11,>=2.10->tensorflow) (0.6.1)\n",
        "    Requirement already satisfied: google-auth<3,>=1.6.3 in c:\\users\\dineshraja\\anaconda3\\lib\\site-packages (from tensorboard<2.11,>=2.10->tensorflow) (2.12.0)\n",
        "    Requirement already satisfied: cachetools<6.0,>=2.0.0 in c:\\users\\dineshraja\\anaconda3\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.11,>=2.10->tensorflow) (5.2.0)\n",
        "    Requirement already satisfied: pyasn1-modules>=0.2.1 in c:\\users\\dineshraja\\anaconda3\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.11,>=2.10->tensorflow) (0.2.8)\n",
        "    Requirement already satisfied: rsa<5,>=3.1.4 in c:\\users\\dineshraja\\anaconda3\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.11,>=2.10->tensorflow) (4.9)\n",
        "    Requirement already satisfied: requests-oauthlib>=0.7.0 in c:\\users\\dineshraja\\anaconda3\\lib\\site-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.11,>=2.10->tensorflow) (1.3.1)\n",
        "    Requirement already satisfied: importlib-metadata>=4.4 in c:\\users\\dineshraja\\anaconda3\\lib\\site-packages (from markdown>=2.6.8->tensorboard<2.11,>=2.10->tensorflow) (4.12.0)\n",
        "    Requirement already satisfied: zipp>=0.5 in c:\\users\\dineshraja\\anaconda3\\lib\\site-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<2.11,>=2.10->tensorflow) (3.4.1)\n",
        "    Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in c:\\users\\dineshraja\\anaconda3\\lib\\site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.11,>=2.10->tensorflow) (0.4.8)\n",
        "    Requirement already satisfied: chardet<5,>=3.0.2 in c:\\users\\dineshraja\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.11,>=2.10->tensorflow) (4.0.0)\n",
        "    Requirement already satisfied: idna<3,>=2.5 in c:\\users\\dineshraja\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.11,>=2.10->tensorflow) (2.10)\n",
        "    Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\dineshraja\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.11,>=2.10->tensorflow) (2020.12.5)\n",
        "    Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\dineshraja\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.11,>=2.10->tensorflow) (1.26.4)\n",
        "    Requirement already satisfied: oauthlib>=3.0.0 in c:\\users\\dineshraja\\anaconda3\\lib\\site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.11,>=2.10->tensorflow) (3.2.1)\n",
        "    Requirement already satisfied: pyparsing>=2.0.2 in c:\\users\\dineshraja\\anaconda3\\lib\\site-packages (from packaging->tensorflow) (2.4.7)\n",
        "\n",
        "In \\[2\\]:\n",
        "\n",
        "    # Import required lib\n",
        "\n",
        "    from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "In \\[3\\]:\n",
        "\n",
        "    # Initializing augmentation for training variable\n",
        "\n",
        "    train_datagen = ImageDataGenerator(rescale=1./255,\n",
        "                                       zoom_range=0.2,\n",
        "                                       horizontal_flip=True)\n",
        "\n",
        "In \\[4\\]:\n",
        "\n",
        "    # Initializing augmentation for testing variable\n",
        "\n",
        "    test_datagen = ImageDataGenerator(rescale=1./255,\n",
        "                                      zoom_range=0.2,\n",
        "                                      channel_shift_range=0.2,\n",
        "                                      horizontal_flip=True,\n",
        "                                      vertical_flip=True,\n",
        "                                      validation_split=0.3)\n",
        "\n",
        "In \\[5\\]:\n",
        "\n",
        "    # Passing training data for training variable (augmentation)\n",
        "\n",
        "    xtrain = train_datagen.flow_from_directory(r'D:\\IBM 7th sem project\\Assignments\\Flowers-Dataset\\flowers\\training',\n",
        "                                               target_size=(224,224),\n",
        "                                               class_mode='categorical',\n",
        "                                               batch_size=100)\n",
        "\n",
        "    Found 4317 images belonging to 5 classes.\n",
        "\n",
        "In \\[6\\]:\n",
        "\n",
        "    # Passing testing data for testing variable (augmentation)\n",
        "\n",
        "    xtest = test_datagen.flow_from_directory(r'D:\\IBM 7th sem project\\Assignments\\Flowers-Dataset\\flowers\\testing',\n",
        "                                               target_size=(224,224),\n",
        "                                               class_mode='categorical',\n",
        "                                               batch_size=100)\n",
        "\n",
        "    Found 2223 images belonging to 5 classes.\n",
        "\n",
        "**3. Create Model**<a href=\"https://github.com/IBM-EPBL/IBM-Project-1257-1658381885/blob/24330d3bc5de5f89f6317e12ffdcb3110a96f37a/Assignments/Dineshraja%20V/#3.--Create-Model\" class=\"anchor-link\">¶</a>\n",
        "=========================================================================================================================================================================================================\n",
        "\n",
        "CNN Model<a href=\"https://github.com/IBM-EPBL/IBM-Project-1257-1658381885/blob/24330d3bc5de5f89f6317e12ffdcb3110a96f37a/Assignments/Dineshraja%20V/#CNN-Model\" class=\"anchor-link\">¶</a>\n",
        "========================================================================================================================================================================================\n",
        "\n",
        "In \\[7\\]:\n",
        "\n",
        "    from tensorflow.keras.models import Sequential\n",
        "    from tensorflow.keras.layers import Convolution2D,MaxPooling2D,Flatten,Dense\n",
        "\n",
        "**4. Add Layers (Convolution,MaxPooling,Flatten,Dense-(Hidden Layers),Output)**<a href=\"https://github.com/IBM-EPBL/IBM-Project-1257-1658381885/blob/24330d3bc5de5f89f6317e12ffdcb3110a96f37a/Assignments/Dineshraja%20V/#4.-Add-Layers-(Convolution,MaxPooling,Flatten,Dense-(Hidden-Layers),Output)\" class=\"anchor-link\">¶</a>\n",
        "================================================================================================================================================================================================================================================================================================================================\n",
        "\n",
        "In \\[8\\]:\n",
        "\n",
        "    # CNN block \n",
        "\n",
        "    model = Sequential() # Initializing sequential model \n",
        "    model.add(Convolution2D(32,(3,3),activation='relu',input_shape=(224,224,3))) # Convolution layer \n",
        "    model.add(MaxPooling2D(pool_size=(2, 2))) # Max pooling layer \n",
        "    model.add(Flatten()) # Flatten layer \n",
        "    model.add(Dense(300,activation='relu')) # Hidden layer 1\n",
        "    model.add(Dense(150,activation='relu')) # Hidden layer 2\n",
        "    model.add(Dense(5,activation='softmax')) # Output layer \n",
        "\n",
        "**5. Compile The Model**<a href=\"https://github.com/IBM-EPBL/IBM-Project-1257-1658381885/blob/24330d3bc5de5f89f6317e12ffdcb3110a96f37a/Assignments/Dineshraja%20V/#5.-Compile-The-Model\" class=\"anchor-link\">¶</a>\n",
        "==================================================================================================================================================================================================================\n",
        "\n",
        "In \\[9\\]:\n",
        "\n",
        "    # Compile model\n",
        "\n",
        "    model.compile(optimizer='adam',loss='categorical_crossentropy',metrics=['accuracy'])\n",
        "\n",
        "**6. Fit The Model**<a href=\"https://github.com/IBM-EPBL/IBM-Project-1257-1658381885/blob/24330d3bc5de5f89f6317e12ffdcb3110a96f37a/Assignments/Dineshraja%20V/#6.-Fit-The-Model\" class=\"anchor-link\">¶</a>\n",
        "==========================================================================================================================================================================================================\n",
        "\n",
        "In \\[10\\]:\n",
        "\n",
        "    # Training model\n",
        "\n",
        "    model.fit_generator(xtrain,\n",
        "                        steps_per_epoch=len(xtrain),\n",
        "                        epochs=25,\n",
        "                        validation_data=xtest,\n",
        "                        validation_steps=len(xtest))\n",
        "\n",
        "    <ipython-input-10-576ef5e755f6>:3: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
        "      model.fit_generator(xtrain,\n",
        "\n",
        "    Epoch 1/25\n",
        "    44/44 [==============================] - 117s 3s/step - loss: 5.6398 - accuracy: 0.3287 - val_loss: 1.3520 - val_accuracy: 0.4575\n",
        "    Epoch 2/25\n",
        "    44/44 [==============================] - 112s 3s/step - loss: 1.1739 - accuracy: 0.5219 - val_loss: 1.1479 - val_accuracy: 0.5488\n",
        "    Epoch 3/25\n",
        "    44/44 [==============================] - 118s 3s/step - loss: 1.0188 - accuracy: 0.6071 - val_loss: 1.0331 - val_accuracy: 0.5830\n",
        "    Epoch 4/25\n",
        "    44/44 [==============================] - 126s 3s/step - loss: 0.9498 - accuracy: 0.6359 - val_loss: 0.9704 - val_accuracy: 0.6239\n",
        "    Epoch 5/25\n",
        "    44/44 [==============================] - 131s 3s/step - loss: 0.8810 - accuracy: 0.6713 - val_loss: 1.0078 - val_accuracy: 0.6014\n",
        "    Epoch 6/25\n",
        "    44/44 [==============================] - 128s 3s/step - loss: 0.8393 - accuracy: 0.6903 - val_loss: 0.9089 - val_accuracy: 0.6622\n",
        "    Epoch 7/25\n",
        "    44/44 [==============================] - 129s 3s/step - loss: 0.7675 - accuracy: 0.7079 - val_loss: 0.8869 - val_accuracy: 0.6491\n",
        "    Epoch 8/25\n",
        "    44/44 [==============================] - 128s 3s/step - loss: 0.7596 - accuracy: 0.7114 - val_loss: 0.8658 - val_accuracy: 0.6608\n",
        "    Epoch 9/25\n",
        "    44/44 [==============================] - 150s 3s/step - loss: 0.6901 - accuracy: 0.7422 - val_loss: 0.8240 - val_accuracy: 0.6824\n",
        "    Epoch 10/25\n",
        "    44/44 [==============================] - 139s 3s/step - loss: 0.6763 - accuracy: 0.7533 - val_loss: 0.8795 - val_accuracy: 0.6820\n",
        "    Epoch 11/25\n",
        "    44/44 [==============================] - 148s 3s/step - loss: 0.6316 - accuracy: 0.7735 - val_loss: 0.8400 - val_accuracy: 0.6941\n",
        "    Epoch 12/25\n",
        "    44/44 [==============================] - 162s 4s/step - loss: 0.5978 - accuracy: 0.7820 - val_loss: 0.7907 - val_accuracy: 0.7121\n",
        "    Epoch 13/25\n",
        "    44/44 [==============================] - 153s 3s/step - loss: 0.5670 - accuracy: 0.7878 - val_loss: 0.8167 - val_accuracy: 0.7072\n",
        "    Epoch 14/25\n",
        "    44/44 [==============================] - 141s 3s/step - loss: 0.5349 - accuracy: 0.8059 - val_loss: 0.8180 - val_accuracy: 0.7130\n",
        "    Epoch 15/25\n",
        "    44/44 [==============================] - 149s 3s/step - loss: 0.5349 - accuracy: 0.8084 - val_loss: 0.7545 - val_accuracy: 0.7215\n",
        "    Epoch 16/25\n",
        "    44/44 [==============================] - 139s 3s/step - loss: 0.4779 - accuracy: 0.8290 - val_loss: 0.7599 - val_accuracy: 0.7260\n",
        "    Epoch 17/25\n",
        "    44/44 [==============================] - 160s 4s/step - loss: 0.4655 - accuracy: 0.8374 - val_loss: 0.7777 - val_accuracy: 0.7090\n",
        "    Epoch 18/25\n",
        "    44/44 [==============================] - 153s 3s/step - loss: 0.4528 - accuracy: 0.8358 - val_loss: 0.7656 - val_accuracy: 0.7422\n",
        "    Epoch 19/25\n",
        "    44/44 [==============================] - 163s 4s/step - loss: 0.4479 - accuracy: 0.8411 - val_loss: 0.8146 - val_accuracy: 0.7319\n",
        "    Epoch 20/25\n",
        "    44/44 [==============================] - 152s 3s/step - loss: 0.4188 - accuracy: 0.8562 - val_loss: 0.7321 - val_accuracy: 0.7476\n",
        "    Epoch 21/25\n",
        "    44/44 [==============================] - 192s 4s/step - loss: 0.3963 - accuracy: 0.8564 - val_loss: 0.7239 - val_accuracy: 0.7445\n",
        "    Epoch 22/25\n",
        "    44/44 [==============================] - 168s 4s/step - loss: 0.3738 - accuracy: 0.8624 - val_loss: 0.7413 - val_accuracy: 0.7481\n",
        "    Epoch 23/25\n",
        "    44/44 [==============================] - 152s 3s/step - loss: 0.3581 - accuracy: 0.8700 - val_loss: 0.8223 - val_accuracy: 0.7301\n",
        "    Epoch 24/25\n",
        "    44/44 [==============================] - 162s 4s/step - loss: 0.3573 - accuracy: 0.8714 - val_loss: 0.6871 - val_accuracy: 0.7773\n",
        "    Epoch 25/25\n",
        "    44/44 [==============================] - 152s 3s/step - loss: 0.3086 - accuracy: 0.8967 - val_loss: 0.7519 - val_accuracy: 0.7580\n",
        "\n",
        "Out\\[10\\]:\n",
        "\n",
        "    <keras.callbacks.History at 0x16329827ee0>\n",
        "\n",
        "**7. Save The Model**<a href=\"https://github.com/IBM-EPBL/IBM-Project-1257-1658381885/blob/24330d3bc5de5f89f6317e12ffdcb3110a96f37a/Assignments/Dineshraja%20V/#7.-Save-The-Model\" class=\"anchor-link\">¶</a>\n",
        "============================================================================================================================================================================================================\n",
        "\n",
        "In \\[11\\]:\n",
        "\n",
        "    # Save model\n",
        "\n",
        "    model.save('flowers.h5')\n",
        "\n",
        "**8. Test The Model**<a href=\"https://github.com/IBM-EPBL/IBM-Project-1257-1658381885/blob/24330d3bc5de5f89f6317e12ffdcb3110a96f37a/Assignments/Dineshraja%20V/#8.-Test-The-Model\" class=\"anchor-link\">¶</a>\n",
        "============================================================================================================================================================================================================\n",
        "\n",
        "In \\[12\\]:\n",
        "\n",
        "    from tensorflow.keras.preprocessing import image  # Importing req. lib\n",
        "    import numpy as np\n",
        "\n",
        "    # Testing 1\n",
        "\n",
        "    img = image.load_img(r\"D:\\IBM 7th sem project\\Assignments\\tulip.jpg\",target_size=(224,224))\n",
        "    x = image.img_to_array(img)\n",
        "    x = np.expand_dims(x,axis=0)\n",
        "    pred = np.argmax(model.predict(x))\n",
        "    op = ['Daisy','Dandelion','Rose','Sunflower','Tulip']\n",
        "    print(pred)\n",
        "    print(op[pred])\n",
        "\n",
        "    1/1 [==============================] - 0s 200ms/step\n",
        "    4\n",
        "    Tulip\n",
        "\n",
        "In \\[13\\]:\n",
        "\n",
        "    xtrain.class_indices\n",
        "\n",
        "Out\\[13\\]:\n",
        "\n",
        "    {'daisy': 0, 'dandelion': 1, 'rose': 2, 'sunflower': 3, 'tulip': 4}\n",
        "\n",
        "In \\[15\\]:\n",
        "\n",
        "    # Testing 2\n",
        "\n",
        "    img = image.load_img(r\"D:\\IBM 7th sem project\\Assignments\\sunflower.jpg\",target_size=(224,224))\n",
        "    x = image.img_to_array(img)\n",
        "    x = np.expand_dims(x,axis=0)\n",
        "    pred = np.argmax(model.predict(x))\n",
        "    op = ['Daisy','Dandelion','Rose','Sunflower','Tulip']\n",
        "    print(pred)\n",
        "    print(op[pred])\n",
        "\n",
        "    1/1 [==============================] - 0s 100ms/step\n",
        "    3\n",
        "    Sunflower\n",
        "\n",
        "In \\[16\\]:\n",
        "\n",
        "    # Testing 3\n",
        "\n",
        "    img = image.load_img(r\"D:\\IBM 7th sem project\\Assignments\\daisy.jpg\",target_size=(224,224))\n",
        "    x = image.img_to_array(img)\n",
        "    x = np.expand_dims(x,axis=0)\n",
        "    pred = np.argmax(model.predict(x))\n",
        "    op = ['Daisy','Dandelion','Rose','Sunflower','Tulip']\n",
        "    print(pred)\n",
        "    print(op[pred])\n",
        "\n",
        "    1/1 [==============================] - 0s 96ms/step\n",
        "    0\n",
        "    Daisy\n",
        "\n",
        "In \\[18\\]:\n",
        "\n",
        "    # Testing 4\n",
        "\n",
        "    img = image.load_img(r\"D:\\IBM 7th sem project\\Assignments\\rose.jpg\",target_size=(224,224))\n",
        "    x = image.img_to_array(img)\n",
        "    x = np.expand_dims(x,axis=0)\n",
        "    pred = np.argmax(model.predict(x))\n",
        "    op = ['Daisy','Dandelion','Rose','Sunflower','Tulip']\n",
        "    print(pred)\n",
        "    print(op[pred])\n",
        "\n",
        "    1/1 [==============================] - 0s 114ms/step\n",
        "    2\n",
        "    Rose"
      ],
      "id": "jIagCbF67CoG"
    }
  ],
  "nbformat": 4,
  "nbformat_minor": 5,
  "metadata": {
    "colab": {
      "provenance": []
    }
  }
}